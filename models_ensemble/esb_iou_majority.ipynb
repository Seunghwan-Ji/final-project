{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <수행 방법 요약>\n",
    "# 이미지에서 각 모델들이 인식한 객체들에게서 바운딩된 박스, 신뢰도, 라벨들을 추출한다.\n",
    "# 모든 박스를 서로 한 쌍씩 겹침 정도, 즉 iou를 계산한다.\n",
    "# iou를 1에서 뺀 값이 특정 수치보다 작으면 많이 겹쳤다고 판단한다.\n",
    "# 서로 많이 겹쳐진 박스들끼리 그룹화를 한다.\n",
    "# 각 그룹에서 박스들의 좌표의 평균을 최종 박스 좌표로 결정한다.\n",
    "# 각 그룹에서 박스들의 신뢰도의 평균을 최종 신뢰도로 결정한다.\n",
    "# 각 그룹에서 박스들의 라벨 이름중 빈도수가 높은것을 최종 라벨 이름으로 결정한다.(다수결)\n",
    "# 이미지에 최종 박스 좌표 위치에 사각형을 그리고, 신뢰도와 라벨 이름을 텍스트로 표시한다.\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from collections import Counter, defaultdict\n",
    "import cv2\n",
    "\n",
    "# 모델 파일명 리스트(밴: model10)\n",
    "model_files = [f'models/model{model_number}.pt' for model_number in [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12]]\n",
    "\n",
    "# 모델 로드 및 names 저장\n",
    "models = []\n",
    "model_names = {}\n",
    "\n",
    "# 모델파일 이름, 모델, 클래스 저장\n",
    "for model_file in model_files:\n",
    "    model = YOLO(model_file)\n",
    "    models.append((model_file, model)) # 모델 파일 이름도 같이 저장함\n",
    "    model_names[model_file] = model.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 모델 예측 수행, 결과 담기\n",
    "def ensemble_predict(image):\n",
    "    results = []\n",
    "    detection_counts = []\n",
    "    for model in models:\n",
    "        print(f'\\n{model[0]}', end=\"\")\n",
    "        result = model[1].predict(image, conf=0.5)\n",
    "        results.append(result)\n",
    "        # 각 모델에서 감지한 바운딩 박스의 수\n",
    "        detection_counts.append(len(result[0].boxes))\n",
    "    print('\\nNumber of objects detected by each model:')\n",
    "    print(detection_counts)\n",
    "\n",
    "    # 과반수 이상의 모델이 바운딩 박스가 없는 경우\n",
    "    if sum(count == 0 for count in detection_counts) >= len(models) / 2: # count가 0인 모델의 수가 과반수 이상인지 검사\n",
    "        return [], [], []  # 감지된 객체가 없는 경우, 빈 결과 반환\n",
    "\n",
    "    combined_results = combine_results(*results)  # final_boxes, final_confidences, final_labels\n",
    "    return combined_results\n",
    "\n",
    "# 각 결과에서 바운딩 박스, 신뢰도, 라벨 추출\n",
    "def combine_results(*results):\n",
    "    combined_boxes = []\n",
    "    combined_confidences = []\n",
    "    combined_labels = defaultdict(list)  # 같은 박스 위치에 여러 레이블을 저장하기 위한 딕셔너리\n",
    "\n",
    "    # 각 모델의 결과에서 바운딩 박스를 추출하여 결합\n",
    "    for model_index, result_list in enumerate(results):\n",
    "        model_name = models[model_index][0]\n",
    "        for result in result_list:\n",
    "            for box in result.boxes:\n",
    "                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "                conf = box.conf[0].cpu().numpy()\n",
    "                class_id = int(box.cls[0].cpu().numpy())\n",
    "\n",
    "                # 클래스 번호를 클래스 이름으로 변환\n",
    "                class_name = model_names[model_name][class_id]\n",
    "\n",
    "                combined_boxes.append([x1, y1, x2, y2])\n",
    "                combined_confidences.append(conf)\n",
    "                combined_labels[(x1, y1, x2, y2)].append(class_name)\n",
    "\n",
    "    # if len(combined_boxes) == 0:  # combined_boxes가 비어 있는 경우를 처리합니다.\n",
    "    #     return [], [], []\n",
    "\n",
    "    combined_boxes = np.array(combined_boxes)\n",
    "    combined_confidences = np.array(combined_confidences)\n",
    "\n",
    "    # 박스를 그룹화하여 다수결로 라벨 결정\n",
    "    final_boxes = []\n",
    "    final_confidences = []\n",
    "    final_labels = []\n",
    "\n",
    "    box_groups = group_boxes_by_overlap(combined_boxes)  # 겹치는 박스 번호들끼리 그룹화한 리스트\n",
    "\n",
    "    if len(box_groups) > 0:\n",
    "        for group in box_groups:\n",
    "            group_boxes = combined_boxes[group]  # 그룹의 각 번호에 해당하는 박스들의 좌표배열\n",
    "            group_confidences = combined_confidences[group]  # 그룹의 각 번호에 해당하는 박스들의 신뢰도\n",
    "            group_labels = [combined_labels[tuple(box)] for box in group_boxes]  # combined_labels = {(박스 좌표배열) : 라벨이름}\n",
    "\n",
    "            # 그룹 내에서 평균 박스와 평균 신뢰도를 계산\n",
    "            avg_box = np.mean(group_boxes, axis=0)\n",
    "            avg_conf = np.mean(group_confidences)\n",
    "\n",
    "            # 각 박스에 대해 다수결로 레이블 결정\n",
    "            flattened_labels = [label for sublist in group_labels for label in sublist]  # 라벨이름들이 저장된 리스트\n",
    "            flattened_labels = [label.lower() for label in flattened_labels] # 라벨이름 모두 소문자로 통일\n",
    "            print(flattened_labels)\n",
    "            most_common_label_and_count = Counter(flattened_labels).most_common(1) # 가장 빈도수가 높은 라벨 추출\n",
    "            most_common_label = most_common_label_and_count[0][0]\n",
    "            label_count = most_common_label_and_count[0][1]\n",
    "            if label_count >= 2: # 라벨의 빈도수가 2 이상이면 통과\n",
    "                final_boxes.append(avg_box)\n",
    "                final_confidences.append(avg_conf)\n",
    "                final_labels.append(most_common_label)\n",
    "            else:\n",
    "                return [], [], []\n",
    "\n",
    "        final_boxes = np.array(final_boxes)\n",
    "        final_confidences = np.array(final_confidences)\n",
    "        final_labels = np.array(final_labels)\n",
    "    else:\n",
    "        return [], [], []\n",
    "\n",
    "    return final_boxes, final_confidences, final_labels\n",
    "\n",
    "# 박스가 겹치는 그룹을 찾는 함수(각 그룹 안에는 박스 번호들이 있음)\n",
    "def group_boxes_by_overlap(boxes, iou_threshold=0.4):\n",
    "    distances = cdist(boxes, boxes, lambda x, y: 1 - iou(x, y))  # 두 박스간의 겹침 정도(비율)가 클수록 1에서 뺀 값이 작아지므로 거리가 작아진다.\n",
    "    groups = []\n",
    "    visited = set()\n",
    "\n",
    "    for i in range(len(boxes)):  # i: 현재 박스의 인덱스\n",
    "        if i in visited:  # 이미 방문된 박스 집합(visited)에 있다면 다음 반복으로 넘어감\n",
    "            continue\n",
    "        group = [i]  # 현재 박스 번호를 포함한 그룹 생성\n",
    "        visited.add(i)  # 현재 박스 번호를 집합에 추가\n",
    "        for j in range(i + 1, len(boxes)):  # 현재 박스의 다음 박스 번호부터 순회\n",
    "            if j in visited:  # 이미 방문된 박스 집합(visited)에 있다면 다음 반복으로 넘어감\n",
    "                continue\n",
    "            if distances[i, j] < iou_threshold:  # 박스 i와 j의 거리가 iou_threshold보다 작다면, 두 박스가 많이 겹친다고 판단함\n",
    "                group.append(j)  # 박스 번호 j를 group에 추가\n",
    "                visited.add(j)  # 집합에도 추가\n",
    "        groups.append(group)  # 그룹을 groups에 추가\n",
    "    print('\\nbox number groups:')\n",
    "    print(groups)\n",
    "    print('\\nlabels of passed groups:')\n",
    "\n",
    "    groups = [group for group in groups if len(group) >= 3] # 그룹내 박스가 3개 이상인 것만 통과\n",
    "    return groups\n",
    "\n",
    "# IoU (Intersection over Union) 계산 함수\n",
    "# 객체 탐지 및 이미지 분석에서 두 바운딩 박스 간의 겹침 정도를 측정하는 지표,\n",
    "# IoU는 두 박스의 교차 영역과 두 박스의 합집합 영역 간의 비율을 나타냄\n",
    "def iou(box1, box2):\n",
    "    x1 = max(box1[0], box2[0])  # x1 vs X1, 더 큰 값이 교집합 영역 좌상단 x좌표\n",
    "    y1 = max(box1[1], box2[1])  # y1 vs Y1, 더 큰 값이 교집합 영역 좌상단 y좌표\n",
    "    x2 = min(box1[2], box2[2])  # x2 vs X2, 더 작은 값이 교집합 영역 우하단 x좌표\n",
    "    y2 = min(box1[3], box2[3])  # y2 vs Y2, 더 작은 값이 교집합 영역 우하단 y좌표\n",
    "\n",
    "    intersection = max(0, x2 - x1) * max(0, y2 - y1)  # 교집합 영역 가로길이 * 교집합 영역 세로길이 = 교집합 영역의 전체 면적\n",
    "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])  # 박스1의 가로길이 * 세로길이 = 박스1의 전체 면적\n",
    "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])  # 박스2의 가로길이 * 세로길이 = 박스2의 전체 면적\n",
    "    union = box1_area + box2_area - intersection  # 두 박스의 합집합 영역에서 교집합 영역을 뺀 값\n",
    "\n",
    "    return intersection / union if union > 0 else 0  # 교집합 면적을 합집합 면적으로 나눈값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "models/model1.pt\n",
      "0: 640x640 (no detections), 142.0ms\n",
      "Speed: 5.0ms preprocess, 142.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "models/model2.pt\n",
      "0: 640x640 2 potatos, 89.6ms\n",
      "Speed: 4.5ms preprocess, 89.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "models/model3.pt\n",
      "0: 640x640 2 potatos, 82.6ms\n",
      "Speed: 5.0ms preprocess, 82.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "models/model4.pt\n",
      "0: 640x640 2 potatos, 22.0ms\n",
      "Speed: 2.0ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "models/model5.pt\n",
      "0: 640x640 2 Eggs, 19.5ms\n",
      "Speed: 1.0ms preprocess, 19.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "models/model6.pt\n",
      "0: 640x640 (no detections), 18.5ms\n",
      "Speed: 1.0ms preprocess, 18.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "models/model7.pt\n",
      "0: 640x640 2 potatos, 19.5ms\n",
      "Speed: 1.5ms preprocess, 19.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "models/model8.pt\n",
      "0: 640x640 (no detections), 22.0ms\n",
      "Speed: 1.0ms preprocess, 22.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "models/model9.pt\n",
      "0: 640x640 1 potato, 18.5ms\n",
      "Speed: 2.0ms preprocess, 18.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "models/model11.pt\n",
      "0: 640x640 2 Potatos, 18.5ms\n",
      "Speed: 2.0ms preprocess, 18.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "models/model12.pt\n",
      "0: 640x640 2 Potatos, 18.5ms\n",
      "Speed: 2.0ms preprocess, 18.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "Number of objects detected by each model:\n",
      "[0, 2, 2, 2, 2, 0, 2, 0, 1, 2, 2]\n",
      "\n",
      "box number groups:\n",
      "[[0, 3, 4, 6, 8, 12, 13], [1, 2, 5, 7, 9, 10, 11, 14]]\n",
      "\n",
      "labels of passed groups:\n",
      "['potato', 'potato', 'potato', 'egg', 'potato', 'potato', 'potato']\n",
      "['potato', 'potato', 'potato', 'egg', 'potato', 'potato', 'potato', 'potato']\n",
      "\n",
      "final conclusion:\n",
      "Box: [     200.66      288.84      585.08      582.45], Confidence: 0.9563531875610352, Label: potato\n",
      "Box: [     47.179      70.709      446.58      370.15], Confidence: 0.910297155380249, Label: potato\n",
      "\n",
      "Annotated image saved as potato_with_boxes_majority.jpg\n"
     ]
    }
   ],
   "source": [
    "# 이미지 파일을 읽어오기\n",
    "image_path = 'potato.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# 이미지에 대해 앙상블 예측 수행\n",
    "combined_results = ensemble_predict(image) # final_boxes, final_confidences, final_labels\n",
    "\n",
    "# 결과 출력 및 이미지에 그리기\n",
    "boxes, confidences, labels = combined_results\n",
    "\n",
    "print(\"\\nfinal conclusion:\")\n",
    "if len(boxes) > 0 and len(confidences) > 0 and len(labels) > 0:\n",
    "    for box, conf, label in zip(boxes, confidences, labels):\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "        label_name = label  # 이미 label은 클래스 이름입니다.\n",
    "\n",
    "        # 레이블 이름이 확인되었으면, 이미지를 수정합니다.\n",
    "        if label_name is not None:\n",
    "            # 사각형 테두리 그리는 함수(사각형을 그릴 이미지, 사각형 좌상단 좌표, 사각형 우하단 좌표, 사각형 색, 사각형 두께)\n",
    "            cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "            # 텍스트 추가하는 함수(텍스트 추가할 이미지, 텍스트 문자열, 텍스트 시작점, 텍스트 폰트, 텍스트 크기, 텍스트 색상, 텍스트 두께)\n",
    "            cv2.putText(image, f'{label_name} {conf:.2f}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "            # 박스 좌표, 신뢰도, 라벨이름 출력\n",
    "            print(f'Box: {box}, Confidence: {conf}, Label: {label_name}')\n",
    "\n",
    "# 수정된 이미지 저장\n",
    "output_image_path = 'potato_with_boxes_majority.jpg'\n",
    "cv2.imwrite(output_image_path, image)\n",
    "print(f\"\\nAnnotated image saved as {output_image_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "models/model1.pt\n",
      "0: 384x640 1 carrot, 94.1ms\n",
      "Speed: 2.0ms preprocess, 94.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "models/model2.pt\n",
      "0: 384x640 1 Mushroom, 103.0ms\n",
      "Speed: 3.0ms preprocess, 103.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "models/model3.pt\n",
      "0: 384x640 (no detections), 66.0ms\n",
      "Speed: 3.0ms preprocess, 66.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "models/model4.pt\n",
      "0: 384x640 (no detections), 73.1ms\n",
      "Speed: 3.0ms preprocess, 73.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "models/model5.pt\n",
      "0: 384x640 (no detections), 18.5ms\n",
      "Speed: 1.5ms preprocess, 18.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "models/model6.pt\n",
      "0: 384x640 (no detections), 23.5ms\n",
      "Speed: 1.0ms preprocess, 23.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "models/model7.pt\n",
      "0: 384x640 1 mushroom, 18.5ms\n",
      "Speed: 1.0ms preprocess, 18.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "models/model8.pt\n",
      "0: 384x640 (no detections), 20.6ms\n",
      "Speed: 1.1ms preprocess, 20.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "models/model9.pt\n",
      "0: 384x640 2 potatos, 19.0ms\n",
      "Speed: 1.0ms preprocess, 19.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "models/model11.pt\n",
      "0: 384x640 (no detections), 20.0ms\n",
      "Speed: 1.0ms preprocess, 20.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "models/model12.pt\n",
      "0: 384x640 (no detections), 18.1ms\n",
      "Speed: 2.0ms preprocess, 18.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Number of objects detected by each model:\n",
      "[1, 1, 0, 0, 0, 0, 1, 0, 2, 0, 0]\n",
      "\n",
      "final conclusion for 19511_30300_2213.png:\n",
      "Annotated image saved as google_test_images/predict_majority\\predict_19511_30300_2213.png\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "models/model1.pt\n",
      "0: 512x640 2 green_beanss, 19.1ms\n",
      "Speed: 2.0ms preprocess, 19.1ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "models/model2.pt\n",
      "0: 512x640 1 chicken, 19.0ms\n",
      "Speed: 2.0ms preprocess, 19.0ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "models/model3.pt\n",
      "0: 512x640 1 carrot, 19.1ms\n",
      "Speed: 2.0ms preprocess, 19.1ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "models/model4.pt\n",
      "0: 512x640 1 mushroom, 19.1ms\n",
      "Speed: 1.0ms preprocess, 19.1ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "models/model5.pt\n",
      "0: 512x640 (no detections), 18.0ms\n",
      "Speed: 2.1ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "models/model6.pt\n",
      "0: 512x640 3 tofus, 18.5ms\n",
      "Speed: 2.0ms preprocess, 18.5ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "models/model7.pt\n",
      "0: 512x640 1 chicken thigh, 1 tofu, 18.5ms\n",
      "Speed: 2.0ms preprocess, 18.5ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "models/model8.pt\n",
      "0: 512x640 1 onion, 19.5ms\n",
      "Speed: 2.5ms preprocess, 19.5ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "models/model9.pt\n",
      "0: 512x640 1 rice, 19.8ms\n",
      "Speed: 2.0ms preprocess, 19.8ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "models/model11.pt\n",
      "0: 512x640 1 Cheese, 21.1ms\n",
      "Speed: 1.0ms preprocess, 21.1ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "models/model12.pt\n",
      "0: 512x640 (no detections), 19.1ms\n",
      "Speed: 2.0ms preprocess, 19.1ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "Number of objects detected by each model:\n",
      "[2, 1, 1, 1, 0, 3, 2, 1, 1, 1, 0]\n",
      "\n",
      "box number groups:\n",
      "[[0], [1], [2, 3, 8], [4], [5], [6], [7], [9, 12], [10], [11]]\n",
      "\n",
      "labels of passed groups:\n",
      "['chicken', 'carrot', 'chicken thigh']\n",
      "\n",
      "final conclusion for 2024042201965_0.jpg:\n",
      "Annotated image saved as google_test_images/predict_majority\\predict_2024042201965_0.jpg\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "models/model1.pt\n",
      "0: 384x640 1 spinach, 1 strawberries, 2 tomatos, 20.2ms\n",
      "Speed: 2.0ms preprocess, 20.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "models/model2.pt\n",
      "0: 384x640 1 10_tangerine, 1 bell pepper, 1 broccoli, 1 grapes, 1 tomato, 20.1ms\n",
      "Speed: 2.0ms preprocess, 20.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "models/model3.pt\n",
      "0: 384x640 1 egg, 2 onions, 1 potato, 6 tomatos, 20.1ms\n",
      "Speed: 1.0ms preprocess, 20.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "models/model4.pt\n",
      "0: 384x640 (no detections), 23.1ms\n",
      "Speed: 2.0ms preprocess, 23.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "models/model5.pt\n",
      "0: 384x640 2 Apples, 1 Broccoli, 1 Egg, 2 Tomatos, 20.1ms\n",
      "Speed: 1.0ms preprocess, 20.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "models/model6.pt\n",
      "0: 384x640 (no detections), 19.5ms\n",
      "Speed: 1.0ms preprocess, 19.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "models/model7.pt\n",
      "0: 384x640 1 broccoli, 3 mushrooms, 1 onion, 2 peppers, 18.5ms\n",
      "Speed: 2.0ms preprocess, 18.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "models/model8.pt\n",
      "0: 384x640 1 green_onion, 20.5ms\n",
      "Speed: 1.5ms preprocess, 20.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "models/model9.pt\n",
      "0: 384x640 7 tomatos, 20.7ms\n",
      "Speed: 2.0ms preprocess, 20.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "models/model11.pt\n",
      "0: 384x640 2 Tomatos, 20.3ms\n",
      "Speed: 1.0ms preprocess, 20.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "models/model12.pt\n",
      "0: 384x640 2 Eggs, 21.1ms\n",
      "Speed: 1.0ms preprocess, 21.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Number of objects detected by each model:\n",
      "[4, 5, 10, 0, 6, 0, 7, 1, 7, 2, 2]\n",
      "\n",
      "box number groups:\n",
      "[[0, 4, 19, 29], [1, 5, 25], [2], [3], [6, 31], [7, 12, 23, 28, 33], [8, 27], [9, 42], [10, 34, 41], [11, 24, 37, 40], [13, 22, 36], [14, 26], [15, 38], [16, 20, 35], [17], [18], [21, 39, 43], [30], [32]]\n",
      "\n",
      "labels of passed groups:\n",
      "['spinach', 'broccoli', 'broccoli', 'broccoli']\n",
      "['tomato', 'bell pepper', 'pepper']\n",
      "\n",
      "final conclusion for 28625_52668_1144.jpg:\n",
      "Annotated image saved as google_test_images/predict_majority\\predict_28625_52668_1144.jpg\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "models/model1.pt\n",
      "0: 480x640 (no detections), 20.0ms\n",
      "Speed: 1.0ms preprocess, 20.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "models/model2.pt\n",
      "0: 480x640 10 onions, 19.5ms\n",
      "Speed: 1.0ms preprocess, 19.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "models/model3.pt\n",
      "0: 480x640 9 onions, 18.5ms\n",
      "Speed: 1.0ms preprocess, 18.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "models/model4.pt\n",
      "0: 480x640 19 onions, 26.1ms\n",
      "Speed: 1.0ms preprocess, 26.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "models/model5.pt\n",
      "0: 480x640 12 Onions, 20.6ms\n",
      "Speed: 2.0ms preprocess, 20.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "models/model6.pt\n",
      "0: 480x640 3 meats, 19.5ms\n",
      "Speed: 1.0ms preprocess, 19.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "models/model7.pt\n",
      "0: 480x640 14 onions, 19.5ms\n",
      "Speed: 1.0ms preprocess, 19.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "models/model8.pt\n",
      "0: 480x640 (no detections), 19.5ms\n",
      "Speed: 1.0ms preprocess, 19.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "models/model9.pt\n",
      "0: 480x640 16 onions, 19.2ms\n",
      "Speed: 1.0ms preprocess, 19.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "models/model11.pt\n",
      "0: 480x640 13 Onions, 17.5ms\n",
      "Speed: 1.7ms preprocess, 17.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "models/model12.pt\n",
      "0: 480x640 1 Egg, 20.5ms\n",
      "Speed: 1.0ms preprocess, 20.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Number of objects detected by each model:\n",
      "[0, 10, 9, 19, 12, 3, 14, 0, 16, 13, 1]\n",
      "\n",
      "box number groups:\n",
      "[[0, 10, 19, 41, 53, 68, 85], [1, 15, 21, 38, 61, 67, 84], [2, 17, 28, 42, 62, 71, 86], [3, 11, 36, 40, 51, 57, 69, 83], [4, 18, 24, 48, 66, 80, 91], [5, 12, 25, 46, 58, 72, 89], [6, 34, 43, 59, 77, 90], [7, 65], [8, 16, 30, 52, 55, 73, 94], [9, 14, 27, 54, 74, 87], [13, 29, 75], [20, 39, 60, 70, 95], [22, 78], [23, 49, 64], [26, 79, 88], [31, 50], [32, 47, 82, 93], [33, 76], [35, 44], [37], [45, 63], [56], [81], [92], [96]]\n",
      "\n",
      "labels of passed groups:\n",
      "['onion', 'onion', 'onion', 'onion', 'onion', 'onion', 'onion']\n",
      "['onion', 'onion', 'onion', 'onion', 'onion', 'onion', 'onion']\n",
      "['onion', 'onion', 'onion', 'onion', 'onion', 'onion', 'onion']\n",
      "['onion', 'onion', 'onion', 'onion', 'meat', 'onion', 'onion', 'onion']\n",
      "['onion', 'onion', 'onion', 'onion', 'onion', 'onion', 'onion']\n",
      "['onion', 'onion', 'onion', 'onion', 'onion', 'onion', 'onion']\n",
      "['onion', 'onion', 'onion', 'onion', 'onion', 'onion']\n",
      "['onion', 'onion', 'onion', 'meat', 'onion', 'onion', 'onion']\n",
      "['onion', 'onion', 'onion', 'onion', 'onion', 'onion']\n",
      "['onion', 'onion', 'onion']\n",
      "['onion', 'onion', 'onion', 'onion', 'onion']\n",
      "['onion', 'onion', 'onion']\n",
      "['onion', 'onion', 'onion']\n",
      "['onion', 'onion', 'onion', 'onion']\n",
      "\n",
      "final conclusion for 4214_6486_2627.png:\n",
      "Box: [     250.16      115.89      352.85      233.26], Confidence: 0.9327906370162964, Label: onion\n",
      "Box: [     260.74      230.43       348.1      311.67], Confidence: 0.891532301902771, Label: onion\n",
      "Box: [     68.125      253.69      173.64      315.96], Confidence: 0.8645724654197693, Label: onion\n",
      "Box: [     106.85       135.6      242.61       264.6], Confidence: 0.8494553565979004, Label: onion\n",
      "Box: [     384.06      164.72      444.78      246.71], Confidence: 0.6926413178443909, Label: onion\n",
      "Box: [     248.35       42.56       331.5      127.66], Confidence: 0.8275942206382751, Label: onion\n",
      "Box: [     6.0169      106.68      67.612      204.13], Confidence: 0.7755758166313171, Label: onion\n",
      "Box: [     383.57      66.738      444.85      155.75], Confidence: 0.73417729139328, Label: onion\n",
      "Box: [     162.45      58.812      247.86      143.32], Confidence: 0.8151697516441345, Label: onion\n",
      "Box: [     322.89      78.396       396.2      189.98], Confidence: 0.8690598607063293, Label: onion\n",
      "Box: [     5.8038      7.8457      71.547      113.25], Confidence: 0.8162275552749634, Label: onion\n",
      "Box: [     110.27      4.4043      185.93      90.319], Confidence: 0.7206754684448242, Label: onion\n",
      "Box: [     325.06      199.14      407.72      291.49], Confidence: 0.7787538170814514, Label: onion\n",
      "Box: [     5.8031      240.59      86.635      316.51], Confidence: 0.6634340882301331, Label: onion\n",
      "Annotated image saved as google_test_images/predict_majority\\predict_4214_6486_2627.png\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "models/model1.pt\n",
      "0: 448x640 1 onion, 20.0ms\n",
      "Speed: 2.0ms preprocess, 20.0ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model2.pt\n",
      "0: 448x640 (no detections), 20.5ms\n",
      "Speed: 2.0ms preprocess, 20.5ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model3.pt\n",
      "0: 448x640 5 potatos, 20.0ms\n",
      "Speed: 1.0ms preprocess, 20.0ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model4.pt\n",
      "0: 448x640 19 potatos, 23.5ms\n",
      "Speed: 1.0ms preprocess, 23.5ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model5.pt\n",
      "0: 448x640 2 Onions, 17.5ms\n",
      "Speed: 1.0ms preprocess, 17.5ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model6.pt\n",
      "0: 448x640 (no detections), 20.0ms\n",
      "Speed: 1.0ms preprocess, 20.0ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model7.pt\n",
      "0: 448x640 1 mushroom, 2 potatos, 20.0ms\n",
      "Speed: 1.0ms preprocess, 20.0ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model8.pt\n",
      "0: 448x640 1 green_onion, 20.5ms\n",
      "Speed: 1.0ms preprocess, 20.5ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model9.pt\n",
      "0: 448x640 15 potatos, 18.5ms\n",
      "Speed: 1.0ms preprocess, 18.5ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model11.pt\n",
      "0: 448x640 2 Potatos, 1 Radish, 18.5ms\n",
      "Speed: 1.0ms preprocess, 18.5ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model12.pt\n",
      "0: 448x640 3 Potatos, 18.5ms\n",
      "Speed: 1.0ms preprocess, 18.5ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "Number of objects detected by each model:\n",
      "[1, 0, 5, 19, 2, 0, 3, 1, 15, 3, 3]\n",
      "\n",
      "box number groups:\n",
      "[[0], [1, 14, 41], [2, 10, 28, 33], [3, 19, 35], [4, 17, 27, 34], [5, 9, 36], [6, 31, 46, 51], [7, 32], [8, 25, 37, 48, 50], [11], [12, 26, 42], [13, 38], [15, 40, 49], [16, 44], [18, 39], [20, 43], [21], [22, 45], [23], [24], [29], [30], [47]]\n",
      "\n",
      "labels of passed groups:\n",
      "['potato', 'potato', 'potato']\n",
      "['potato', 'potato', 'potato', 'potato']\n",
      "['potato', 'potato', 'potato']\n",
      "['potato', 'potato', 'potato', 'potato']\n",
      "['potato', 'potato', 'potato']\n",
      "['potato', 'potato', 'potato', 'potato']\n",
      "['potato', 'onion', 'potato', 'potato', 'potato']\n",
      "['potato', 'onion', 'potato']\n",
      "['potato', 'potato', 'potato']\n",
      "\n",
      "final conclusion for 560_03.jpg:\n",
      "Box: [     297.44      196.45      351.88      248.31], Confidence: 0.7564545273780823, Label: potato\n",
      "Box: [     341.84      204.12      387.78      254.63], Confidence: 0.7869623899459839, Label: potato\n",
      "Box: [     413.49      198.24      470.49      244.57], Confidence: 0.7424610257148743, Label: potato\n",
      "Box: [     315.04      159.35       365.1      204.26], Confidence: 0.75559401512146, Label: potato\n",
      "Box: [      384.6      217.54       437.1       255.8], Confidence: 0.7137188911437988, Label: potato\n",
      "Box: [     156.12      277.42      222.09      344.96], Confidence: 0.7354589104652405, Label: potato\n",
      "Box: [     181.94      213.44       244.7      260.75], Confidence: 0.7527220249176025, Label: potato\n",
      "Box: [     120.11       214.2      168.89      253.52], Confidence: 0.7208077907562256, Label: potato\n",
      "Box: [     98.034      259.38      157.09      304.89], Confidence: 0.7373679280281067, Label: potato\n",
      "Annotated image saved as google_test_images/predict_majority\\predict_560_03.jpg\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "models/model1.pt\n",
      "0: 448x640 (no detections), 18.5ms\n",
      "Speed: 1.0ms preprocess, 18.5ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model2.pt\n",
      "0: 448x640 7 egg_s, 18.5ms\n",
      "Speed: 1.0ms preprocess, 18.5ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model3.pt\n",
      "0: 448x640 (no detections), 19.5ms\n",
      "Speed: 1.0ms preprocess, 19.5ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model4.pt\n",
      "0: 448x640 4 eggs, 19.5ms\n",
      "Speed: 1.0ms preprocess, 19.5ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model5.pt\n",
      "0: 448x640 1 Tomato, 19.5ms\n",
      "Speed: 1.0ms preprocess, 19.5ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model6.pt\n",
      "0: 448x640 (no detections), 18.5ms\n",
      "Speed: 2.0ms preprocess, 18.5ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model7.pt\n",
      "0: 448x640 5 eggs, 19.5ms\n",
      "Speed: 1.0ms preprocess, 19.5ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model8.pt\n",
      "0: 448x640 1 ham, 19.6ms\n",
      "Speed: 1.0ms preprocess, 19.6ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model9.pt\n",
      "0: 448x640 1 chicken, 5 eggs, 18.0ms\n",
      "Speed: 2.0ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model11.pt\n",
      "0: 448x640 (no detections), 18.1ms\n",
      "Speed: 1.4ms preprocess, 18.1ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model12.pt\n",
      "0: 448x640 2 Eggs, 20.2ms\n",
      "Speed: 2.0ms preprocess, 20.2ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "Number of objects detected by each model:\n",
      "[0, 7, 0, 4, 1, 0, 5, 1, 6, 0, 2]\n",
      "\n",
      "box number groups:\n",
      "[[0, 10, 13, 18], [1, 7, 16, 21], [2, 14, 22], [3, 8, 12, 20, 24], [4, 15, 19], [5, 6], [9], [11], [17, 23], [25]]\n",
      "\n",
      "labels of passed groups:\n",
      "['egg_', 'egg', 'egg', 'egg']\n",
      "['egg_', 'egg', 'egg', 'egg']\n",
      "['egg_', 'egg', 'egg']\n",
      "['egg_', 'egg', 'egg', 'egg', 'egg']\n",
      "['egg_', 'egg', 'egg']\n",
      "\n",
      "final conclusion for 61644_118877_4950.jpg:\n",
      "Box: [     178.94      203.96      262.43      286.19], Confidence: 0.7916166186332703, Label: egg\n",
      "Box: [     53.855      189.88      133.69      271.16], Confidence: 0.80665522813797, Label: egg\n",
      "Box: [     326.62      153.07      402.08      223.82], Confidence: 0.8054253458976746, Label: egg\n",
      "Box: [     99.183      240.49      187.12      315.07], Confidence: 0.8291541337966919, Label: egg\n",
      "Box: [     256.21      182.91      333.96      249.34], Confidence: 0.8062968850135803, Label: egg\n",
      "Annotated image saved as google_test_images/predict_majority\\predict_61644_118877_4950.jpg\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "models/model1.pt\n",
      "0: 480x640 (no detections), 20.5ms\n",
      "Speed: 2.0ms preprocess, 20.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "models/model2.pt\n",
      "0: 480x640 1 avocado, 22.5ms\n",
      "Speed: 2.0ms preprocess, 22.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "models/model3.pt\n",
      "0: 480x640 (no detections), 18.5ms\n",
      "Speed: 2.0ms preprocess, 18.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "models/model4.pt\n",
      "0: 480x640 (no detections), 18.5ms\n",
      "Speed: 1.0ms preprocess, 18.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "models/model5.pt\n",
      "0: 480x640 (no detections), 19.2ms\n",
      "Speed: 1.0ms preprocess, 19.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "models/model6.pt\n",
      "0: 480x640 (no detections), 20.1ms\n",
      "Speed: 1.0ms preprocess, 20.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "models/model7.pt\n",
      "0: 480x640 (no detections), 19.0ms\n",
      "Speed: 1.0ms preprocess, 19.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "models/model8.pt\n",
      "0: 480x640 (no detections), 17.5ms\n",
      "Speed: 2.0ms preprocess, 17.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "models/model9.pt\n",
      "0: 480x640 (no detections), 20.5ms\n",
      "Speed: 2.0ms preprocess, 20.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "models/model11.pt\n",
      "0: 480x640 (no detections), 19.5ms\n",
      "Speed: 2.0ms preprocess, 19.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "models/model12.pt\n",
      "0: 480x640 (no detections), 19.5ms\n",
      "Speed: 1.0ms preprocess, 19.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Number of objects detected by each model:\n",
      "[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "final conclusion for 9861_16853_218.jpg:\n",
      "Annotated image saved as google_test_images/predict_majority\\predict_9861_16853_218.jpg\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "models/model1.pt\n",
      "0: 352x640 4 butters, 21.0ms\n",
      "Speed: 1.0ms preprocess, 21.0ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "models/model2.pt\n",
      "0: 352x640 (no detections), 18.0ms\n",
      "Speed: 2.0ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "models/model3.pt\n",
      "0: 352x640 (no detections), 18.5ms\n",
      "Speed: 1.0ms preprocess, 18.5ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "models/model4.pt\n",
      "0: 352x640 1 onion, 18.5ms\n",
      "Speed: 1.0ms preprocess, 18.5ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "models/model5.pt\n",
      "0: 352x640 4 Tomatos, 20.5ms\n",
      "Speed: 1.0ms preprocess, 20.5ms inference, 2.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "models/model6.pt\n",
      "0: 352x640 4 tomatos, 19.6ms\n",
      "Speed: 2.0ms preprocess, 19.6ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "models/model7.pt\n",
      "0: 352x640 (no detections), 20.5ms\n",
      "Speed: 1.5ms preprocess, 20.5ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "models/model8.pt\n",
      "0: 352x640 (no detections), 18.5ms\n",
      "Speed: 2.0ms preprocess, 18.5ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "models/model9.pt\n",
      "0: 352x640 4 tomatos, 18.5ms\n",
      "Speed: 1.0ms preprocess, 18.5ms inference, 2.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "models/model11.pt\n",
      "0: 352x640 1 Tomato, 18.5ms\n",
      "Speed: 1.5ms preprocess, 18.5ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "models/model12.pt\n",
      "0: 352x640 (no detections), 20.5ms\n",
      "Speed: 1.5ms preprocess, 20.5ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "Number of objects detected by each model:\n",
      "[4, 0, 0, 1, 4, 4, 0, 0, 4, 1, 0]\n",
      "\n",
      "box number groups:\n",
      "[[0, 5, 9, 14], [1, 6, 11, 15], [2, 4, 8, 10, 13, 17], [3, 7, 12, 16]]\n",
      "\n",
      "labels of passed groups:\n",
      "['butter', 'tomato', 'tomato', 'tomato']\n",
      "['butter', 'tomato', 'tomato', 'tomato']\n",
      "['butter', 'onion', 'tomato', 'tomato', 'tomato', 'tomato']\n",
      "['butter', 'tomato', 'tomato', 'tomato']\n",
      "\n",
      "final conclusion for groro_bb0d30be04a040fbb7c3afef57a2de87.jpg:\n",
      "Box: [     337.13      298.39      492.12      437.57], Confidence: 0.8776971101760864, Label: tomato\n",
      "Box: [     155.03      294.74      317.19      439.52], Confidence: 0.8501099944114685, Label: tomato\n",
      "Box: [     529.93      304.73      691.14      443.06], Confidence: 0.757142961025238, Label: tomato\n",
      "Box: [     730.43      306.69      881.38      445.15], Confidence: 0.7777040004730225, Label: tomato\n",
      "Annotated image saved as google_test_images/predict_majority\\predict_groro_bb0d30be04a040fbb7c3afef57a2de87.jpg\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "models/model1.pt\n",
      "0: 448x640 3 green_beanss, 2 spinachs, 19.5ms\n",
      "Speed: 1.0ms preprocess, 19.5ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model2.pt\n",
      "0: 448x640 (no detections), 19.5ms\n",
      "Speed: 1.0ms preprocess, 19.5ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model3.pt\n",
      "0: 448x640 2 onions, 1 potato, 18.0ms\n",
      "Speed: 1.0ms preprocess, 18.0ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model4.pt\n",
      "0: 448x640 (no detections), 20.5ms\n",
      "Speed: 1.0ms preprocess, 20.5ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model5.pt\n",
      "0: 448x640 1 Egg, 24.5ms\n",
      "Speed: 2.5ms preprocess, 24.5ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model6.pt\n",
      "0: 448x640 (no detections), 18.5ms\n",
      "Speed: 1.0ms preprocess, 18.5ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model7.pt\n",
      "0: 448x640 1 melon, 23.0ms\n",
      "Speed: 1.0ms preprocess, 23.0ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model8.pt\n",
      "0: 448x640 2 pears, 18.5ms\n",
      "Speed: 1.0ms preprocess, 18.5ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model9.pt\n",
      "0: 448x640 1 cabbage, 1 potato, 20.0ms\n",
      "Speed: 1.0ms preprocess, 20.0ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model11.pt\n",
      "0: 448x640 6 Chilli Peppers, 18.5ms\n",
      "Speed: 1.0ms preprocess, 18.5ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model12.pt\n",
      "0: 448x640 1 Potato, 18.6ms\n",
      "Speed: 1.0ms preprocess, 18.6ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "Number of objects detected by each model:\n",
      "[5, 0, 3, 0, 1, 0, 1, 2, 2, 6, 1]\n",
      "\n",
      "box number groups:\n",
      "[[0, 3, 11, 17], [1, 2, 7, 9, 13, 14], [4, 10, 18], [5, 12, 15], [6, 19], [8, 16, 20]]\n",
      "\n",
      "labels of passed groups:\n",
      "['spinach', 'green_beans', 'pear', 'chilli pepper']\n",
      "\n",
      "final conclusion for restmb_idxmake.jpg:\n",
      "Annotated image saved as google_test_images/predict_majority\\predict_restmb_idxmake.jpg\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "models/model1.pt\n",
      "0: 448x640 (no detections), 18.0ms\n",
      "Speed: 1.0ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model2.pt\n",
      "0: 448x640 1 lemon, 20.1ms\n",
      "Speed: 1.0ms preprocess, 20.1ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model3.pt\n",
      "0: 448x640 2 onions, 20.1ms\n",
      "Speed: 1.0ms preprocess, 20.1ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model4.pt\n",
      "0: 448x640 1 chicken, 18.5ms\n",
      "Speed: 1.0ms preprocess, 18.5ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model5.pt\n",
      "0: 448x640 1 Onion, 19.5ms\n",
      "Speed: 1.0ms preprocess, 19.5ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model6.pt\n",
      "0: 448x640 (no detections), 18.5ms\n",
      "Speed: 1.0ms preprocess, 18.5ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model7.pt\n",
      "0: 448x640 1 chicken, 1 lemon, 21.1ms\n",
      "Speed: 1.0ms preprocess, 21.1ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model8.pt\n",
      "0: 448x640 (no detections), 19.1ms\n",
      "Speed: 1.0ms preprocess, 19.1ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model9.pt\n",
      "0: 448x640 1 bread, 21.2ms\n",
      "Speed: 1.0ms preprocess, 21.2ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model11.pt\n",
      "0: 448x640 1 duck, 1 lemon, 19.1ms\n",
      "Speed: 1.0ms preprocess, 19.1ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model12.pt\n",
      "0: 448x640 (no detections), 18.5ms\n",
      "Speed: 1.0ms preprocess, 18.5ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "Number of objects detected by each model:\n",
      "[0, 1, 2, 1, 1, 0, 2, 0, 1, 2, 0]\n",
      "\n",
      "box number groups:\n",
      "[[0, 6, 9], [1, 3, 4, 5, 7, 8], [2]]\n",
      "\n",
      "labels of passed groups:\n",
      "['lemon', 'lemon', 'lemon']\n",
      "['onion', 'chicken', 'onion', 'chicken', 'bread', 'duck']\n",
      "\n",
      "final conclusion for style_6306fb0f7c43f-700x467.jpeg:\n",
      "Box: [      458.5      324.52      611.67      465.39], Confidence: 0.8545905947685242, Label: lemon\n",
      "Box: [     20.309      24.163      483.18      434.79], Confidence: 0.8583228588104248, Label: onion\n",
      "Annotated image saved as google_test_images/predict_majority\\predict_style_6306fb0f7c43f-700x467.jpeg\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "models/model1.pt\n",
      "0: 416x640 1 carrot, 1 spinach, 24.5ms\n",
      "Speed: 1.0ms preprocess, 24.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "models/model2.pt\n",
      "0: 416x640 5 cucumbers, 21.2ms\n",
      "Speed: 1.0ms preprocess, 21.2ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "models/model3.pt\n",
      "0: 416x640 3 cucumbers, 21.1ms\n",
      "Speed: 1.0ms preprocess, 21.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "models/model4.pt\n",
      "0: 416x640 3 cucumbers, 20.1ms\n",
      "Speed: 1.0ms preprocess, 20.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "models/model5.pt\n",
      "0: 416x640 1 Brussel Sprout, 18.5ms\n",
      "Speed: 1.0ms preprocess, 18.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "models/model6.pt\n",
      "0: 416x640 (no detections), 18.0ms\n",
      "Speed: 2.0ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "models/model7.pt\n",
      "0: 416x640 1 cucumber, 18.5ms\n",
      "Speed: 1.0ms preprocess, 18.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "models/model8.pt\n",
      "0: 416x640 (no detections), 20.1ms\n",
      "Speed: 1.0ms preprocess, 20.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "models/model9.pt\n",
      "0: 416x640 2 cucumbers, 21.2ms\n",
      "Speed: 1.0ms preprocess, 21.2ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "models/model11.pt\n",
      "0: 416x640 5 Cucumbers, 20.1ms\n",
      "Speed: 1.0ms preprocess, 20.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "models/model12.pt\n",
      "0: 416x640 (no detections), 19.5ms\n",
      "Speed: 1.0ms preprocess, 19.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "Number of objects detected by each model:\n",
      "[2, 5, 3, 3, 1, 0, 1, 0, 2, 5, 0]\n",
      "\n",
      "box number groups:\n",
      "[[0], [1], [2, 14, 16, 18], [3], [4], [5, 19], [6], [7, 21], [8, 11, 15, 17], [9, 10, 20], [12], [13]]\n",
      "\n",
      "labels of passed groups:\n",
      "['cucumber', 'cucumber', 'cucumber', 'cucumber']\n",
      "['cucumber', 'cucumber', 'cucumber', 'cucumber']\n",
      "['cucumber', 'cucumber', 'cucumber']\n",
      "\n",
      "final conclusion for unnamed.jpg:\n",
      "Box: [     292.11       118.6      373.78      247.32], Confidence: 0.7513286471366882, Label: cucumber\n",
      "Box: [     5.7422     0.59458      281.02      202.22], Confidence: 0.8496959805488586, Label: cucumber\n",
      "Box: [      126.7      43.055       297.1      172.64], Confidence: 0.7993736267089844, Label: cucumber\n",
      "Annotated image saved as google_test_images/predict_majority\\predict_unnamed.jpg\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "models/model1.pt\n",
      "0: 448x640 (no detections), 19.5ms\n",
      "Speed: 1.5ms preprocess, 19.5ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model2.pt\n",
      "0: 448x640 1 beef, 1 salmon, 19.0ms\n",
      "Speed: 1.0ms preprocess, 19.0ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model3.pt\n",
      "0: 448x640 1 carrot, 24.0ms\n",
      "Speed: 2.0ms preprocess, 24.0ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model4.pt\n",
      "0: 448x640 (no detections), 20.5ms\n",
      "Speed: 1.0ms preprocess, 20.5ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model5.pt\n",
      "0: 448x640 1 Apple, 19.5ms\n",
      "Speed: 2.0ms preprocess, 19.5ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model6.pt\n",
      "0: 448x640 1 meat, 20.0ms\n",
      "Speed: 1.0ms preprocess, 20.0ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model7.pt\n",
      "0: 448x640 1 beef, 18.5ms\n",
      "Speed: 2.0ms preprocess, 18.5ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model8.pt\n",
      "0: 448x640 2 hams, 18.5ms\n",
      "Speed: 1.0ms preprocess, 18.5ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model9.pt\n",
      "0: 448x640 1 bread, 1 meat, 19.5ms\n",
      "Speed: 2.0ms preprocess, 19.5ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model11.pt\n",
      "0: 448x640 1 Pork, 19.5ms\n",
      "Speed: 1.0ms preprocess, 19.5ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "models/model12.pt\n",
      "0: 448x640 (no detections), 18.5ms\n",
      "Speed: 2.0ms preprocess, 18.5ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "Number of objects detected by each model:\n",
      "[0, 2, 1, 0, 1, 1, 1, 2, 2, 1, 0]\n",
      "\n",
      "box number groups:\n",
      "[[0], [1, 3, 4, 5, 6, 8, 10], [2], [7], [9]]\n",
      "\n",
      "labels of passed groups:\n",
      "['beef', 'apple', 'meat', 'beef', 'ham', 'meat', 'pork']\n",
      "\n",
      "final conclusion for 다운로드.jpg:\n",
      "Box: [     83.907      103.22      335.34      434.24], Confidence: 0.8552036881446838, Label: beef\n",
      "Annotated image saved as google_test_images/predict_majority\\predict_다운로드.jpg\n",
      "\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 여러 이미지 예측하기\n",
    "\n",
    "import os\n",
    "\n",
    "def process_and_predict_images(image_dir, output_dir):\n",
    "    # 이미지 디렉토리 내 모든 파일 읽기\n",
    "    for filename in os.listdir(image_dir):\n",
    "        image_path = os.path.join(image_dir, filename)\n",
    "        if os.path.isfile(image_path):\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "            if image is not None:\n",
    "                # 이미지에 대해 앙상블 예측 수행\n",
    "                combined_results = ensemble_predict(image)  # final_boxes, final_confidences, final_labels\n",
    "\n",
    "                # 결과 출력 및 이미지에 그리기\n",
    "                boxes, confidences, labels = combined_results\n",
    "\n",
    "                print(f\"\\nfinal conclusion for {filename}:\")\n",
    "                if len(boxes) > 0 and len(confidences) > 0 and len(labels) > 0:\n",
    "                    for box, conf, label in zip(boxes, confidences, labels):\n",
    "                        x1, y1, x2, y2 = map(int, box)\n",
    "                        label_name = label  # 이미 label은 클래스 이름입니다.\n",
    "\n",
    "                        # 레이블 이름이 확인되었으면, 이미지를 수정합니다.\n",
    "                        if label_name is not None:\n",
    "                            # 사각형 테두리 그리는 함수\n",
    "                            cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "                            # 텍스트 추가하는 함수\n",
    "                            cv2.putText(image, f'{label_name} {conf:.2f}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "                            # 박스 좌표, 신뢰도, 라벨이름 출력\n",
    "                            print(f'Box: {box}, Confidence: {conf}, Label: {label_name}')\n",
    "\n",
    "                # 수정된 이미지 저장\n",
    "                output_image_path = os.path.join(output_dir, f\"predict_{filename}\")\n",
    "                cv2.imwrite(output_image_path, image)\n",
    "                print(f\"Annotated image saved as {output_image_path}\")\n",
    "                print('\\n' + '==' * 50)\n",
    "\n",
    "# 이미지 디렉토리와 출력 디렉토리 지정\n",
    "image_dir = 'google_test_images'\n",
    "output_dir = 'google_test_images/predict_majority'\n",
    "\n",
    "# 출력 디렉토리가 존재하지 않으면 생성\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# 이미지 처리 및 예측 수행\n",
    "process_and_predict_images(image_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
